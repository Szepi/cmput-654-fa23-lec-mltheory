\documentclass[twoside]{article}

% We add packages, macros here:
\include{header}

%%
%% ADD PACKAGES here:
%%
%
%\usepackage{amsmath,amsfonts,graphicx}
%
%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%

\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}


%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf CMPUT 654 Fa 23: Theoretical Foundations of Machine Learning \hfill Fall 2023} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Lecturer: #3 \hfill Scribes: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}

   \noindent {\bf Note}: {\it 
   \LaTeX\  template courtesy of UC Berkeley EECS dept. (\href{https://inst.eecs.berkeley.edu/~cs294-8/sp03/Materials/}{link} to directory)
   }

   \noindent {\bf Disclaimer}: {\it These notes have \underline{\textbf{not}} been subjected to the
   usual scrutiny reserved for formal publications. They may be
   distributed outside this class only with the permission of the
   Instructor.} \vspace*{4mm}
}
%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
%%%%%%%%% (To avoid bibliography problems, for now we redefine the \cite command.)
%%%%%%%%% Also commands that create a suitable format for the reference list.
%%%%%%%%\renewcommand{\cite}[1]{[#1]}
%%%%%%%%\def\beginrefs{\begin{list}%
%%%%%%%%        {[\arabic{equation}]}{\usecounter{equation}
%%%%%%%%         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
%%%%%%%%         \setlength{\labelwidth}{1.6truecm}}}
%%%%%%%%\def\endrefs{\end{list}}
%%%%%%%%\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.

\include{theorems}

%\newtheorem{theorem}{Theorem}[lecnum]
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{claim}[theorem]{Claim}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{definition}[theorem]{Definition}
%\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\newcommand\myE{\mathbb{E}}

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{9}{Symmetrization Lemma}{Csaba Szepesv\'ari}{Shuai Liu}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

% **** YOUR NOTES GO HERE:

% Some general latex examples and examples making use of the
% macros follow.  
%**** IN GENERAL, BE BRIEF. LONG SCRIBE NOTES, NO MATTER HOW WELL WRITTEN,
%**** ARE NEVER READ BY ANYBODY.

\section{Motivation and Overview}
Consider the following example. We have $\cX= \R^d$, $\cY=\{0,1\}$ and our function class is $\cF=\{f_w:w\in \R^d\}$ where $f_w=\mathbb I(w^\top x \ge 0)$. In this example, the lower bracketing cover is hard to find. Bracketing cover works but in order to get a better rate, we need some other tools: $L_p$-empirical covering number, uniform entropy ($L_1,L_\infty$) and symmetrization. Back to the example, the set of our function $\cF$ is an infinite set so the covering size has to go to infinity in order to cover $\R^d$ up to $\varepsilon$. However, if we take a closer look at the structure of $\cF$, the behavior of this function class is restrictive, for example, the magnitude does not matter (we only care about the sign of the inner product, which is only relevant to the direction of $w$). What's more, note that with a dataset $(X_i,Y_i)_{i=1}^n$, the number of behaviors, i.e., all possible outcomes that $(Y_i)_{i=1}^n$ can take, could go up to $2^n$. But with a function from $\cF$, the total number of behaviors increases as $n^d$ instead of $2^n$ (we will see that later). This structure could be taken use of to increase the learning efficiency.
\section{Empirical Covering Number}
We start with a pseudo-meric space $(\cX,d)$ where $\cX$ is a set of points and $d:\cX\times\cX\to [0,\infty)$ is a pseudo-meric that satisfies the following properties:
\begin{enumerate}
   \item For all $x\in \cX$, $d(x,x)=0$.
   \item (non-negativity) For all $x,y\in \cX$, $d(x,y)\ge 0$.
   \item (symmetry) For all $x,y\in \cX$, $d(x,y)=d(y,x)$.
   \item (triangle inequality) For all $x,y,z\in \cX$, $d(x,z)\le d(x,y)+d(y,z)$.
\end{enumerate}
Note that it does not satisfy the property that $d(x,y)=0$ only if $x=y$. 
\begin{definition}[$\varepsilon$-cover]
   The $\varepsilon$-cover of $(\cX,d)$ is a finite set $\{x_i\}_{i=1}^n$ such that for all $x\in \cX$, there exists $i\in [n]$ satisfying $d(x,x_i)\le \varepsilon$.
\end{definition}
The empirical cover is w.r.t. the empirical metric, which we define below.
\begin{definition}[Empirical $L_p$ metric]
   Let $\cG\subseteq \R^\cZ$  and $z_{1:n}\subset \cZ^n$. For all $g\in \cG$, the empirical $L_p$-norm $\|\cdot\|_{L_p(z_{1:n})}$ is defined to be
   \begin{equation*}
      \|g\|_{L_p(z_{1:n})}=\left(\frac{1}{n}\sum_{i=1}^n |g(z_i)|^p\right)^{1/p}.
   \end{equation*}
   The empirical $L_p$-norm induces a metric $d$, i.e., for all $g_1,g_2\in \cG$, the empirical $L_p$ metric is defined to be $d(g_1,g_2)=\|g_1-g_2\|_{L_p(z_{1:n})}$.
\end{definition}
Different from bracketing cover, the empirical covering has to be a subset of the whole set. 
As in bracketing number, we define the empirical $L_p$ covering number \[\cN_p(\varepsilon,\cG, z_{1:n})=\min\{n\ge 1:\exists g_1,...,g_n \text{ that forms an $\varepsilon$-cover w.r.t. the empirical $L_p$ metric}\}.\] We further define the uniform empirical $L_p$ covering number as $\cN(\varepsilon,\cG, n)=\sup_{z_{1:n}}\cN_p(\varepsilon,\cG, z_{1:n})$. 

There is a proposition in real analysis about the relationship between $L_p$ and $L_q$ spaces which we state below.
\begin{proposition}
   Let $(\Omega, \Sigma, \mu)$ be a finite measure space and $1\le p\le q\le \infty$. Then $\|\cdot\|_{L_p}\le C\|\cdot\|_{L_q}$, where $C=\mu(\Omega)^{1/p-1/q}$. In particular, if $\mu(\Omega)=1$, then $L_p\le L_q$.
\end{proposition}
The measure corresponding to empirical $L_p$-norm is the mixture of diracs on $z_1,...,z_n$, i.e., $\mu(z)=\frac{1}{n}$ if $z\in \{z_i\}_{i=1}^n $ and $\mu(z)=0$ otherwise. Hence we have the following corollary.
\begin{corollary}
   For $1\le p\le q\le \infty$ and $z_{1:n}\in \cZ^n$, it follows that $L_p(z_{1:n})\le L_q(z_{1:n})$.
\end{corollary}

\section{Symmetrization}
The symmetrization lemma that we are going to display here is counter-intuitive so let's focus on the result itself and we will see why we need it later. We need to first introduce some notations. Let $P\in \cM_1(\cZ)$ be a probability measure and $Z_{1:n}, Z_{1:n}'\sim P$ be i.i.d. samples from $P$ where $Z_{1:n}'$ are called shadow samples. 
As before, we define the empirical measure on $Z_{1:n}, Z_{1:n}'$: \[P_n=\frac{1}{n}\sum_{i=1}^n \delta_{Z_i}, P_n'=\frac{1}{n}\sum_{i=1}^n \delta_{Z_i'}.\]
Take $s\in \{\pm 1\}^d$ and create signed empirical measures \[P_{s,n}=\frac{1}{n}\sum_{i=1}^n s_i\delta_{Z_i}, P_{s,n}'=\frac{1}{n}\sum_{i=1}^ns_i\delta_{Z_i'}.\]

\begin{theorem}[Symmetrization Lemma]\label{thm:sym_lem}
   Let $\sigma\sim \mathrm{Rad}(n)$ be a sample of Rademachar distribution (the discrete uniform distribution over $\{\pm 1\}^n$) that is independent of $Z_{1:n}, Z_{1:n}'$. For $\cF\subseteq \R^{\cZ}$, functions $\psi:\cF\times \cZ^n\to \R$, $\tilde \psi:\cF\times \cZ^{2n}\to\R$ and $\varepsilon>0$, $0<\delta<1$, assume the following holds:
   \begin{enumerate}
      \item[(U)] w.p. $1-\delta$, for all $f\in \cF$, it follows that \[P_{\sigma,n}f\le \psi(f,Z_{1:n})+\varepsilon.\]
      \item[(Sub-additive)] For all $f\in \cF$, $z_{1:2n}\in \cZ^{2n}$, it follows that \[\psi(f,z_{1:n})+\psi(f,z_{n+1:2n})\le \tilde\psi(f,z_{1:2n}).\]
      \item[(S)] For all $f\in \cF$, $z_{1:2n}\in \cZ^{2n}$ and $\pi\in \mathrm{Perm}([2n])$, it follows that
      \[\tilde \psi(f,z_{1:2n})=\tilde \psi(f,z_{\pi(1:2n)})\]
      where $\mathrm{Perm}(A)=\{f:A\to A\vert f \text{ is a bijection}\}$ is the set of all the permutations on a finite set $A$ and $z_{\pi(1:2n)}=z_{\pi(1):\pi(2n)}$.
   \end{enumerate}
   Then w.p. $1-2\delta$, it holds that for all $f\in \cF$,
   \begin{equation*}
      P_n'f\le P_nf+\tilde\psi(f,Z_{1:n}Z_{1:n}')+2\varepsilon.
   \end{equation*}
\end{theorem}
For a fixed $s\in \{\pm 1\}^n$, let \[\cE_s:=\{\forall f\in \cF, P_{s,n}'f-P_{s,n}f\le \tilde\psi(f,Z_{1:n}, Z_{1:n}')+2\varepsilon\}\] and let $\hat \cE$ be defined as \begin{equation}
   {\hat\cE}:={P'_{\sigma,n}f-P_{\sigma,n}f\le \tilde \psi(f,Z_{1:n},Z_{1:n}')+2\varepsilon}\label{eq:ehat}.
\end{equation} We now state an intuitive lemma and delay the proof to the end.
\begin{lemma}
   Under the conditions of \cref{thm:sym_lem}, for all $s\in \{\pm 1\}^n$, $\PP(\cE_s)=\PP(\cE_1)$.\label{lem:helper}
\end{lemma}
\begin{proof}[proof of \cref{thm:sym_lem}]
   Note that we only need to prove that $\PP(\cE_1)\ge 1-2\delta$ by definition. Let $\cE=\{\forall f\in \cF: -P_{\sigma,n}f\le \psi(f,Z_{1:n})+\varepsilon\}$ and $\cE'=\{\forall f\in \cF: P_{\sigma,n}'f\le \psi(f,Z_{1:n}')+\varepsilon\}$. 
   Then from the assumptions specified in \cref{thm:sym_lem}, we can obtain $\PP(\cE)=\PP(\cE')$ because $-P_{\sigma,n}f=P_{-\sigma,n}f$ by definition and $\sigma\stackrel D=-\sigma$, $Z_{1:n}\stackrel{D}{=}Z_{1:n}'$ where $\stackrel{D}{=}$ denotes equality in distribution. Then by union bound, $\tilde \cE=\cE\cap \cE'$ holds w.p. $1-2\delta$. By definition of $\tilde\cE$ and $\hat\cE$, we have that $\tilde\cE\subseteq \hat\cE$ hence $\PP(\hat \cE)\ge \PP(\tilde\cE)\ge 1-2\delta$. Now it suffices to show that $\PP(\hat \cE)=\PP(\cE_1)$. Since $\hat \cE=\cup_{s\in \{\pm 1\}^n}\{\sigma=s\}\cap \hat \cE$,
   \begin{align*}
      \PP(\hat \cE)&=\PP\left(\bigcup_{s\in \{\pm 1\}^n}\{\sigma=s\}\cap \hat\cE\right)\\
      &=\sum_{s\in \{\pm 1\}^n}\PP\left(\{\sigma=s\}\cap \hat\cE\right)\tag{$\{\sigma=s\}$ are disjoint sets}\\
      &=\sum_{s\in \{\pm 1\}^n} \PP\left(\{\sigma=s\}\cap \cE_s\right)\\
      &=\sum_{s\in \{\pm 1\}^n} \PP\left(\{\sigma=s\}\right)\PP\left(\cE_s\right)\tag{independence between $\sigma$ and $Z_{1:n}, Z_{1:n}'$}\\
      &=\frac{1}{2^n}\sum_{s\in \{\pm 1\}^n}\PP(\cE_s)\\
      &=\PP(\cE_1).\tag{\cref{lem:helper}}
   \end{align*}
\end{proof}
\begin{proof}[proof of \cref{lem:helper}]
   Fix $(s_1,...,s_n)=s\in \{\pm 1\}^n$ and let $s_{i,-}=(s_1,...,-s_i,...,s_n)$ be the sign vector that flips $s$ in the $i$-th position. Then it suffices to show that $\PP(\cE_{s})=\PP(\cE_{s_{i,-}})$ for all $i\in [n]$ because for all $s,s'\in \{\pm 1\}^n$, we can transform $\cE_s$ to $\cE_{s'}$ by flipping signs for at most $n$ times without changing the probability. Then for $f\in \cF$, we introduce the abbreviated notation 
   \begin{align*}
      R_{-i}&=(Z_1,\dotsc, Z_{i-1},Z_{i+1},\dotsc, Z_n,Z_1',\dotsc, Z_{i-1}',Z_{i+1}',\dotsc, Z_n'), \\
      U(Z_i,Z_i',R_{-i},f)&=\frac{s_i(f(Z_i)-f(Z_i'))}{n}+\frac{1}{n}\left(\sum_{j\neq i}s_j( f(Z_j')-f(Z_j))\right)\\
      V(Z_i,Z_i',R_{-i},f)&=\tilde\psi(f,Z_{1:n}, Z_{1:n}')+2\varepsilon
   \end{align*} 
   we write out $\cE_s$ and $\cE_{s_{i,-}}$:
   \begin{align*}
      \cE_s&=\left\{\forall f\in \cF:U(Z_i,Z_i',R_{-i},f)\le V(Z_i,Z_i',R_{-i},f)\right\}\\
      \cE_{s_{i,-}}&=\left\{\forall f\in \cF:U(Z_i',Z_i,R_{-i},f)\le V(Z_i,Z_i',R_{-i},f)\right\}
   \end{align*}
   Then by tower rule,
   \begin{align*}
      \PP(\forall f\in \cF:U(Z_i,Z_i',R_{-i},f)\le V(Z_i,Z_i',R_{-i},f))=\E[\PP(\forall f\in \cF:U(Z_i,Z_i',R_{-i},f)\le V(Z_i,Z_i',R_{-i},f)\vert R_{-i})].
   \end{align*}
   It suffices to prove that \[\PP(\forall f\in \cF:U(Z_i,Z_i',R_{-i},f)\le V(Z_i,Z_i',R_{-i},f)\vert R_{-i})=\PP(\forall f\in \cF:U(Z_i',Z_i,R_{-i},f)\le V(Z_i,Z_i',R_{-i},f)\vert R_{-i}).\]
   Assume the existence of the regular conditional distribution $P_{Z_i,Z_i'\vert R}(dz_i,dz_i'|R)$, the LHS can be written as 
   \begin{align*}
      &\int_{\cZ^2}P_{Z_i,Z_i'\vert R}(dz_i,dz_i'|R)\mathbb I(\forall f\in \cF,U(z_i,z_i',R_{-i},f)\le V(z_i,z_i',R_{-i},f))\\
      =&\int_{\cZ^2} P_{Z_i,Z_i'}(dz_i,dz_i')\mathbb I(\forall f\in \cF,U(z_i,z_i',R_{-i},f)\le V(z_i,z_i',R_{-i},f))\tag{Independence}\\
      =&\int_{\cZ^2} P_{Z_i',Z_i}(dz_i',dz_i)\mathbb I(\forall f\in \cF,U(z_i',z_i,R_{-i},f)\le V(z_i',z_i,R_{-i},f))\tag{$(Z_i,Z_i')\stackrel{D}{=}(Z_i',Z_i)$}\\
      =&\int_{\cZ^2}P_{Z_i',Z_i}(dz_i',dz_i)\mathbb I(\forall f\in \cF,U(z_i',z_i,R_{-i},f)\le V(z_i,z_i',R_{-i},f))\tag{Assumption (S)}\\
      =&\int_{\cZ^2}P_{Z_i',Z_i|R}(dz_i',dz_i|R)\mathbb I(\forall f\in \cF,U(z_i',z_i,R_{-i},f)\le V(z_i,z_i',R_{-i},f)),\tag{Independence}
   \end{align*}
   which is RHS by definition.
\end{proof}

\end{document}