\documentclass[twoside]{article}

% We add packages, macros here:
\include{header}

%%
%% ADD PACKAGES here:
%%
%
%\usepackage{amsmath,amsfonts,graphicx}
%
%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%

\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}


%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf CMPUT 654 Fa 23: Theoretical Foundations of Machine Learning \hfill Fall 2023} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Lecturer: #3 \hfill Scribes: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}

   \noindent {\bf Note}: {\it 
   \LaTeX\  template courtesy of UC Berkeley EECS dept. (\href{https://inst.eecs.berkeley.edu/~cs294-8/sp03/Materials/}{link} to directory)
   }

   \noindent {\bf Disclaimer}: {\it These notes have \underline{\textbf{not}} been subjected to the
   usual scrutiny reserved for formal publications. They may be
   distributed outside this class only with the permission of the
   Instructor.} \vspace*{4mm}
}
%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
%%%%%%%%% (To avoid bibliography problems, for now we redefine the \cite command.)
%%%%%%%%% Also commands that create a suitable format for the reference list.
%%%%%%%%\renewcommand{\cite}[1]{[#1]}
%%%%%%%%\def\beginrefs{\begin{list}%
%%%%%%%%        {[\arabic{equation}]}{\usecounter{equation}
%%%%%%%%         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
%%%%%%%%         \setlength{\labelwidth}{1.6truecm}}}
%%%%%%%%\def\endrefs{\end{list}}
%%%%%%%%\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.

\include{theorems}

%\newtheorem{theorem}{Theorem}[lecnum]
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{claim}[theorem]{Claim}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{definition}[theorem]{Definition}
%\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\I}{\mathbb{I}}


\begin{document}
%FILL IN THE RIGHT INFO.
% \lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{15}{Rademacher Complexity (October 26)}{Csaba Szepesv\'ari}{Kushagra Chandak}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

\newcommand{\Rad}{\mathrm{Rad}}

% **** YOUR NOTES GO HERE:

% Some general latex examples and examples making use of the
% macros follow.  
%**** IN GENERAL, BE BRIEF. LONG SCRIBE NOTES, NO MATTER HOW WELL WRITTEN,
%**** ARE NEVER READ BY ANYBODY.

\paragraph{Motivation.} Using Rademacher complexity and chaining, we can get rid of the $\log n$ factor from the uniform convergence bounds. Using Rademacher complexity, we can bound the expected supremum of the underlying empirical process and then use concentration inequalities (like McDiarmid's) to get high probability bounds. First, we define the \emph{uniform convergence complexity (one-sided)} or \emph{expected maximum deviation (one-sided)}.
\begin{definition}[Expected max deviation]
    Let $\cG \subseteq \R^{\cZ}$ and $P \in \cM_1(\cZ)$. Then the expected maximum deviation for class $\cG$ with respect to $P$ is defined as
    \[
        \varepsilon_n(\cG, P) = \EE{\sup_{g \in \cG} Pg - P_n g} \,.
    \]
\end{definition}
\begin{proposition}
    Let $g_n := \argmin_{g\in \cG} P_n g$ be the ERM map. Then
    \[  
        \EE{P g_n} \le \inf_{g \in \cG} Pg + \varepsilon_n(\cG, P) \,.
    \]
\end{proposition}
\begin{proof}
    We start by adding and subtracting $P_n g_n$ to $Pg_n$:
    \begin{align*}
        Pg_n &= P_n g_n + (P - P_n) g_n  \\
        &\le P_n g^* + (P - P_n) g_n \tag{$g^* = \argmin_{g \in \cG} Pg$} \\
        &\le P_n g^* + \sup_{g \in \cG} (P - P_n)g \,.
    \end{align*}
    Taking expectation on both sides gives us the result.
\end{proof}
Now we are ready to define Rademacher complexity and relate it to $\varepsilon_n(\cG, P)$.
\begin{definition}[At sample Rademacher complexity]
    Let $z_{1:n} \in \cZ$ be a fixed sequence of length $n$ in $\cZ$ and $\sigma \sim \Rad(n)$ be a vector of $\set{\pm 1}$ random signs. Then the Rademacher complexity for class $\cG$ at $z_{1:n}$ is defined as
    \[
        R(\cG, z_{1:n}) = \EE{\sup_{g \in \cG} \frac1n \sum_{i=1}^n \sigma_i g(z_i)} \,.
    \]
    For $Z_{1:n} \sim P^{\otimes n}$, the Rademacher complexity for $\cG$ w.r.t to $P$ is defined as
    \[
        R_n(\cG, P) = \E{R(\cG, Z_{1:n})} \,.
    \]
\end{definition}
To relate $\varepsilon_n(\cG, P)$ with $R_n(\cG, P)$, we have the following nice theorem. 
\begin{theorem}
    \[
        \varepsilon_n(\cG, P) \le 2 R_n(\cG, P) \,.
    \]
\end{theorem}

\paragraph{Intuition for Rademacher complexity.} Rademacher complexity measures the ability of $\cG$ to fit to random symmetric noise (Rademacher noise). If $R_n(\cG, P)$ is close to 0, the capacity of the class is bounded ($\cG$ is less expressive) and if $R_n(\cG, P)$ is close to 1 (if  $\cG = \set{-1,1}$) then the capacity of $\cG$ is unbounded. Consider the limiting case $\cG = \set{g}$. In that case,  $R(\cG, z_{1:n}) = \EE{\frac1n \sum_{i=1}^n \sigma_i g(z_i)} = 0$.
 
\end{document}
